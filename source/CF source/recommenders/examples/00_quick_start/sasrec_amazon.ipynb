{"cells":[{"cell_type":"markdown","metadata":{"id":"l_PCtAGpu7Vm"},"source":["# SASRec & SSEPT\n","\n","### Sequential Recommendation Using Transformer \\[1, 6\\]\n","\n","![image.png](attachment:image.png)\n","\n","This is a class of sequential recommendation that uses Transformer \\[2\\] for encoding the users preference represented in terms of a sequence of items purchased/viewed before. Instead of using CNN (Caser \\[3\\]) or RNN (GRU \\[4\\], SLI-Rec \\[5\\] etc.) the approach relies on Transformer based encoder that generates a new representation of the item sequence. Two variants of this Transformer based approaches are included here,\n","\n","- Self-Attentive Sequential Recommendation (or SASRec [1]) that is based on vanilla Transformer and models only the item sequence and\n","- Stochastic Shared Embedding based Personalized Transformer or SSE-PT [6], that also models the users along with the items.\n","\n","This notebook provides an example of necessary steps to train and test either a SASRec or a SSE-PT model."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVLa5DMmN84i","executionInfo":{"status":"ok","timestamp":1702842487599,"user_tz":-420,"elapsed":22915,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"26b01a45-ab3d-4d18-d685-8ec594564682"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab_me/DS300/recommenders/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wifp1cVfN-Wo","executionInfo":{"status":"ok","timestamp":1702842487599,"user_tz":-420,"elapsed":8,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"e370d3c3-9c45-440f-88fe-88d3624e945b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab_me/DS300/recommenders\n"]}]},{"cell_type":"code","source":["!pip install scrapbook\n","!pip install papermill\n","!pip install cornac\n","!pip install retrying\n","!pip install pandera"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBZiLusyOCV0","executionInfo":{"status":"ok","timestamp":1702842537934,"user_tz":-420,"elapsed":50338,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"fad373ba-aedd-4c9c-8aaf-32798e34beed"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scrapbook\n","  Downloading scrapbook-0.5.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from scrapbook) (1.5.3)\n","Collecting papermill (from scrapbook)\n","  Downloading papermill-2.5.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from scrapbook) (4.19.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from scrapbook) (7.34.0)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from scrapbook) (10.0.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (67.7.2)\n","Collecting jedi>=0.16 (from ipython->scrapbook)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->scrapbook) (4.9.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->scrapbook) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->scrapbook) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->scrapbook) (0.32.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->scrapbook) (0.13.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->scrapbook) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->scrapbook) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->scrapbook) (1.23.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (8.1.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (6.0.1)\n","Requirement already satisfied: nbformat>=5.1.2 in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (5.9.2)\n","Requirement already satisfied: nbclient>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (0.9.0)\n","Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (4.66.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (2.31.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (0.4)\n","Requirement already satisfied: tenacity>=5.0.2 in /usr/local/lib/python3.10/dist-packages (from papermill->scrapbook) (8.2.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->scrapbook) (0.8.3)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.2.0->papermill->scrapbook) (6.1.12)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.2.0->papermill->scrapbook) (5.5.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1.2->papermill->scrapbook) (2.19.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->scrapbook) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->scrapbook) (0.2.12)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->scrapbook) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->papermill->scrapbook) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->papermill->scrapbook) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->papermill->scrapbook) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->papermill->scrapbook) (2023.11.17)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill->scrapbook) (23.2.1)\n","Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill->scrapbook) (6.3.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill->scrapbook) (4.1.0)\n","Installing collected packages: jedi, papermill, scrapbook\n","Successfully installed jedi-0.19.1 papermill-2.5.0 scrapbook-0.5.0\n","Requirement already satisfied: papermill in /usr/local/lib/python3.10/dist-packages (2.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from papermill) (8.1.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from papermill) (6.0.1)\n","Requirement already satisfied: nbformat>=5.1.2 in /usr/local/lib/python3.10/dist-packages (from papermill) (5.9.2)\n","Requirement already satisfied: nbclient>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from papermill) (0.9.0)\n","Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from papermill) (4.66.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from papermill) (2.31.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from papermill) (0.4)\n","Requirement already satisfied: tenacity>=5.0.2 in /usr/local/lib/python3.10/dist-packages (from papermill) (8.2.3)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.2.0->papermill) (6.1.12)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.2.0->papermill) (5.5.0)\n","Requirement already satisfied: traitlets>=5.4 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.2.0->papermill) (5.7.1)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1.2->papermill) (2.19.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1.2->papermill) (4.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->papermill) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->papermill) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->papermill) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->papermill) (2023.11.17)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (0.32.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1.2->papermill) (0.13.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (23.2.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (2.8.2)\n","Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (6.3.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill) (4.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (1.16.0)\n","Collecting cornac\n","  Downloading cornac-1.18.0-cp310-cp310-manylinux1_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cornac) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cornac) (1.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cornac) (4.66.1)\n","Collecting powerlaw (from cornac)\n","  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from powerlaw->cornac) (3.7.1)\n","Requirement already satisfied: mpmath in /usr/local/lib/python3.10/dist-packages (from powerlaw->cornac) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->powerlaw->cornac) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->powerlaw->cornac) (1.16.0)\n","Installing collected packages: powerlaw, cornac\n","Successfully installed cornac-1.18.0 powerlaw-1.5\n","Collecting retrying\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying) (1.16.0)\n","Installing collected packages: retrying\n","Successfully installed retrying-1.3.4\n","Collecting pandera\n","  Downloading pandera-0.18.0-py3-none-any.whl (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multimethod (from pandera)\n","  Downloading multimethod-1.10-py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from pandera) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pandera) (23.2)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pandera) (1.5.3)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from pandera) (1.10.13)\n","Collecting typeguard>=3.0.2 (from pandera)\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Collecting typing-inspect>=0.6.0 (from pandera)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from pandera) (1.14.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pandera) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pandera) (2023.3.post1)\n","Collecting typing-extensions>=4.7.0 (from typeguard>=3.0.2->pandera)\n","  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.6.0->pandera)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pandera) (1.16.0)\n","Installing collected packages: typing-extensions, mypy-extensions, multimethod, typing-inspect, typeguard, pandera\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed multimethod-1.10 mypy-extensions-1.0.0 pandera-0.18.0 typeguard-4.1.5 typing-extensions-4.9.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"I0fklSbKu7Vr","executionInfo":{"status":"ok","timestamp":1702842537935,"user_tz":-420,"elapsed":29,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOD9pLAnu7Vt","executionInfo":{"status":"ok","timestamp":1702842549620,"user_tz":-420,"elapsed":11711,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"4c180e11-9aae-465d-9321-c8906216258e"},"outputs":[{"output_type":"stream","name":"stdout","text":["System version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n","Tensorflow version: 2.15.0\n"]}],"source":["import re\n","import sys\n","import os\n","import scrapbook as sb\n","from tempfile import TemporaryDirectory\n","import numpy as np\n","import pandas as pd\n","\n","from collections import defaultdict\n","import tensorflow as tf\n","tf.get_logger().setLevel('ERROR') # only show error messages\n","\n","from recommenders.utils.timer import Timer\n","from recommenders.datasets.amazon_reviews import get_review_data\n","from recommenders.datasets.split_utils import filter_k_core\n","\n","# Transformer Based Models\n","from recommenders.models.sasrec.model import SASREC\n","from recommenders.models.sasrec.ssept import SSEPT\n","\n","# Sampler for sequential prediction\n","from recommenders.models.sasrec.sampler import WarpSampler\n","from recommenders.models.sasrec.util import SASRecDataSet\n","\n","print(\"System version: {}\".format(sys.version))\n","print(\"Tensorflow version: {}\".format(tf.__version__))"]},{"cell_type":"markdown","metadata":{"id":"eex_J3iKu7Vu"},"source":["### Input Parameters"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":["parameters"],"id":"Gsv1WxC4u7Vu","executionInfo":{"status":"ok","timestamp":1702842556555,"user_tz":-420,"elapsed":356,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}}},"outputs":[],"source":["num_epochs = 5\n","batch_size = 128\n","RANDOM_SEED = 100  # Set None for non-deterministic result\n","\n","# data_dir = os.path.join(\"tests\", \"recsys_data\", \"RecSys\", \"SASRec-tf2\", \"data\")\n","data_dir = os.path.join(\"..\", \"..\", \"tests\", \"resources\", \"deeprec\", \"sasrec\")\n","\n","# Amazon Electronics Data\n","dataset = \"reviews_Electronics_5\"\n","\n","lr = 0.001             # learning rate\n","maxlen = 50            # maximum sequence length for each user\n","num_blocks = 2         # number of transformer blocks\n","hidden_units = 100     # number of units in the attention calculation\n","num_heads = 1          # number of attention heads\n","dropout_rate = 0.1     # dropout rate\n","l2_emb = 0.0           # L2 regularization coefficient\n","num_neg_test = 100     # number of negative examples per positive example\n","model_name = 'sasrec'  # 'sasrec' or 'ssept'"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"QysFSUFAu7Vv","executionInfo":{"status":"ok","timestamp":1702842742515,"user_tz":-420,"elapsed":182399,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"90279bd0-f76c-40bc-ed2d-ed345639353f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 484k/484k [00:51<00:00, 9.33kKB/s]\n"]}],"source":["reviews_name = dataset + '.json'\n","outfile = dataset + '.txt'\n","\n","reviews_file = os.path.join(data_dir, reviews_name)\n","if not os.path.exists(reviews_file):\n","    reviews_output = get_review_data(reviews_file)\n","else:\n","    reviews_output = os.path.join(data_dir, dataset+\".json_output\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZctuR__u7Vv"},"outputs":[],"source":["if not os.path.exists(os.path.join(data_dir, outfile)):\n","    df = pd.read_csv(reviews_output, sep=\"\\t\", names=[\"userID\", \"itemID\", \"time\"])\n","    df = filter_k_core(df, 10)  # filter for users & items with less than 10 interactions\n","\n","    user_set, item_set = set(df['userID'].unique()), set(df['itemID'].unique())\n","    user_map = dict()\n","    item_map = dict()\n","    for u, user in enumerate(user_set):\n","        user_map[user] = u+1\n","    for i, item in enumerate(item_set):\n","        item_map[item] = i+1\n","\n","    df[\"userID\"] = df[\"userID\"].apply(lambda x: user_map[x])\n","    df[\"itemID\"] = df[\"itemID\"].apply(lambda x: item_map[x])\n","    df = df.sort_values(by=[\"userID\", \"time\"])\n","    df.drop(columns=[\"time\"], inplace=True)\n","    df.to_csv(os.path.join(data_dir, outfile), sep=\"\\t\", header=False, index=False)"]},{"cell_type":"markdown","metadata":{"id":"CmZ1MqfTu7Vv"},"source":["SASRec requires sequence input and sequence target. Targets are for both positive and negative examples. Inputs to the model are\n","\n","* user's item history as input to the transformer\n","* user's item history shifted (by 1) as target to the transformer (positive examples)\n","* a sequence of items that are not equal to the positive examples (negative examples)\n","\n","From each user's history three samples are created. If there are $N_u$ items for user-$u$ then $N_u-2$ items are used in training and the last two items are used for validation and testing, respectively.\n","\n","## Dataset Format\n","\n","- The input files should have the following format:\n","    - each row has user-id and item-id converted into integers (starting from 1)\n","    - the rows are sorted by user-id and time of interaction\n","    - for every user the last item is used for testing and the last but one is used for validation\n","    - for example, for user `30449` the sorted inputs are:\n","        - `30449 2771`\n","        - `30449 61842`\n","        - `30449 60293`\n","        - `30449 30047`\n","        - `30449 63296`\n","        - `30449 22042`\n","        - `30449 6717`\n","        - `30449 75780`\n","      \n","      then the train inputs are\n","        - [`2771`, `61842`, `60293`, `30047`, `63296`] (input sequence)\n","        - [`61842`, `60293`, `30047`, `63296`, `22042`] (target sequence for positive examples)\n","        - [`1001`, `50490`, `33312`, `19294`, `45342`] (sample negative examples)\n","\n","      and the validation inputs are\n","        - [`2771`, `61842`, `60293`, `30047`, `63296`, `22042`] (input sequence)\n","        - [`61842`, `60293`, `30047`, `63296`, `22042`, `6717`] (target sequence for positive examples)\n","        - [`4401`, `60351`, `22176`, `23456`, `45342`, '1193`] (sample negative examples)\n","        \n","      and the test inputs are\n","        - [`2771`, `61842`, `60293`, `30047`, `63296`, `22042`, `6717`] (input sequence)\n","        - [`61842`, `60293`, `30047`, `63296`, `22042`, `6717`, `75780`] (target sequence for positive examples)\n","        - [`4401`, `60351`, `22176`, `23456`, `45342`, '1193`, `54231`] (sample negative examples)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4AoL_Czu7Vw","executionInfo":{"status":"ok","timestamp":1702472423816,"user_tz":-420,"elapsed":349,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"1c2f758c-4df7-4204-c56b-34a285580d76"},"outputs":[{"output_type":"stream","name":"stdout","text":["../../tests/resources/deeprec/sasrec/reviews_Electronics_5.txt\n","20247 Users and 11589 items\n","average sequence length: 15.16\n"]}],"source":["inp_file = os.path.join(data_dir, dataset + \".txt\")\n","print(inp_file)\n","\n","# initiate a dataset class\n","data = SASRecDataSet(filename=inp_file, col_sep=\"\\t\")\n","\n","# create train, validation and test splits\n","data.split()\n","\n","# some statistics\n","num_steps = int(len(data.user_train) / batch_size)\n","cc = 0.0\n","for u in data.user_train:\n","    cc += len(data.user_train[u])\n","print('%g Users and %g items' % (data.usernum, data.itemnum))\n","print('average sequence length: %.2f' % (cc / len(data.user_train)))"]},{"cell_type":"markdown","metadata":{"id":"SlWEW0aDu7Vw"},"source":["### Model Creation\n","\n","Model parameters are\n","\n","    - number of items\n","    - maximum sequence length of the user interaction history\n","    - number of Transformer blocks\n","    - embedding dimension for item embedding\n","    - dimension of the attention\n","    - number of attention heads\n","    - dropout rate\n","    - dimension of the convolution layers, list\n","    - L_2-regularization coefficient"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3uYIUgeu7Vw"},"outputs":[],"source":["if model_name == 'sasrec':\n","    model = SASREC(item_num=data.itemnum,\n","                   seq_max_len=maxlen,\n","                   num_blocks=num_blocks,\n","                   embedding_dim=hidden_units,\n","                   attention_dim=hidden_units,\n","                   attention_num_heads=num_heads,\n","                   dropout_rate=dropout_rate,\n","                   conv_dims = [100, 100],\n","                   l2_reg=l2_emb,\n","                   num_neg_test=num_neg_test\n","    )\n","elif model_name == \"ssept\":\n","    model = SSEPT(item_num=data.itemnum,\n","                  user_num=data.usernum,\n","                  seq_max_len=maxlen,\n","                  num_blocks=num_blocks,\n","                  # embedding_dim=hidden_units,  # optional\n","                  user_embedding_dim=10,\n","                  item_embedding_dim=hidden_units,\n","                  attention_dim=hidden_units,\n","                  attention_num_heads=num_heads,\n","                  dropout_rate=dropout_rate,\n","                  conv_dims = [110, 110],\n","                  l2_reg=l2_emb,\n","                  num_neg_test=num_neg_test\n","    )\n","else:\n","    print(f\"Model-{model_name} not found\")"]},{"cell_type":"markdown","metadata":{"id":"pEOzZo80u7Vw"},"source":["### Sampler\n","\n","    - the sampler creates negative samples from the training data for each batch\n","    - this is done by looking at the original user interaction history and creating items that are not present at all\n","    - the sampler generates a sequence of negative items of the same length as the original history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfQtIbRZu7Vx"},"outputs":[],"source":["sampler = WarpSampler(data.user_train, data.usernum, data.itemnum, batch_size=batch_size, maxlen=maxlen, n_workers=3)"]},{"cell_type":"markdown","metadata":{"id":"ymFamzR_u7Vx"},"source":["### Model Training\n","\n","    - the loss function is defined over all the negative and positive logits\n","    - a mask has to be applied to indicate the non-zero items present in the output\n","    - we also add the regularization loss here\n","    \n","    - having a train-step signature function can speed up the training process"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVz7Qx4zu7Vx","executionInfo":{"status":"ok","timestamp":1702472879407,"user_tz":-420,"elapsed":455167,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"112d4451-9331-4738-b86c-e93c9ecc55ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["                                                                      "]},{"output_type":"stream","name":"stdout","text":["\n","epoch: 5, test (NDCG@10: 0.3149023118474259, HR@10: 0.5157)\n","Time cost for training is 7.58 mins\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["with Timer() as train_time:\n","    t_test = model.train(data, sampler, num_epochs=num_epochs, batch_size=batch_size, lr=lr, val_epoch=6)\n","\n","print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9cFchg-u7Vx","executionInfo":{"status":"ok","timestamp":1702472879408,"user_tz":-420,"elapsed":17,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"80a7953e-a003-426f-f2c6-613e4b646cd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'ndcg@10': 0.3149023118474259, 'Hit@10': 0.5157}\n"]}],"source":["res_syn = {\"ndcg@10\": t_test[0], \"Hit@10\": t_test[1]}\n","print(res_syn)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"OrMrE0tqu7Vx","executionInfo":{"status":"ok","timestamp":1702472879408,"user_tz":-420,"elapsed":12,"user":{"displayName":"Minh Nguyễn Hoàng","userId":"04529726266143512473"}},"outputId":"8278ced4-baec-4fd0-ae60-6f674ec2024d"},"outputs":[{"output_type":"display_data","data":{"application/scrapbook.scrap.json+json":{"name":"ndcg@10","data":0.3149023118474259,"encoder":"json","version":1}},"metadata":{"scrapbook":{"name":"ndcg@10","data":true,"display":false}}},{"output_type":"display_data","data":{"application/scrapbook.scrap.json+json":{"name":"Hit@10","data":0.5157,"encoder":"json","version":1}},"metadata":{"scrapbook":{"name":"Hit@10","data":true,"display":false}}}],"source":["# Record results with papermill for tests - ignore this cell\n","# sb.glue(\"res_syn\", res_syn)\n","\n","sb.glue(\"ndcg@10\", t_test[0])\n","sb.glue(\"Hit@10\", t_test[1])"]},{"cell_type":"markdown","metadata":{"id":"p4ly2zW_u7Vx"},"source":["## Reference\n","\\[1\\] Wang-Cheng Kang, Julian McAuley: Self-Attentive Sequential Recommendation, arXiv preprint arXiv:1808.09781 (2018) <br>\n","\n","\\[2\\] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998–6008 <br>\n","\n","\\[3\\] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 565–573.\n","\n","\\[4\\] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. arXiv preprint arXiv:1406.1078. 2014.\n","\n","\\[5\\] Zeping Yu, Jianxun Lian, Ahmad Mahmoody, Gongshen Liu, Xing Xie. Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation. In Proceedings of the 28th International Joint Conferences on Artificial Intelligence, IJCAI’19, Pages 4213-4219. AAAI Press, 2019.\n","\n","\\[6\\] Liwei Wu, Shuqing Li, Cho-Jui Hsieh, James Sharpnack. SSE-PT: Sequential Recommendation Via Personalized Transformer. In Fourteenth ACM Conference on Recommender Systems, RecSys'20:, Pages 328–337, 2020."]}],"metadata":{"celltoolbar":"Tags","interpreter":{"hash":"adf311e09e3d70e4b770d653e66a69805c21f44d471e9851e226c4ddc6ad9826"},"kernelspec":{"display_name":"reco_gpu","language":"python","name":"reco_gpu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}